/**
\page code_examples_optimization Optimization Example

On this page, we look at an example application of the sgpp::optimization
module.
The example is written in C++.
However, as the module is also incorporated in pysgpp, one can also use
the Python interface.
Via the Java interface (jsgpp), the module should be usable in MATLAB
if compiled without support for Armadillo and UMFPACK
(see below for instructions).

\section code_examples_optimization_cpp C++

Below, you can find the whole C++ example.
The example minimizes a specific function \f$f\colon [0, 1]^2 \to \mathbb{R}\f$
using sparse grids and the sgpp::optimization module.
For the basic structure of the optimization, please see
\ref module_optimization.

\include optimization.cpp

We will now discuss the example in some detail line by line.

\dontinclude optimization.cpp
\until sgpp_optimization.hpp

We need to include the headers for the sgpp::base and the sgpp::optimization
module.

\until };

The function \f$f\colon [0, 1]^d \to \mathbb{R}\f$ to be minimized
is called "objective function" and has to derive from
sgpp::optimization::ObjectiveFunction.
In the constructor, we give the dimensionality of the domain
(in this case \f$d = 2\f$).
The eval method evaluates the objective function and returns the function
value \f$f(\vec{x})\f$ for a given point \f$\vec{x} \in [0, 1]^d\f$.
The clone method returns a std::unique_ptr to a clone of the object
and is used for parallelization (in case eval is not thread-safe).

\until f, grid, N, gamma

First, we define a grid with modified B-spline basis functions and
an iterative grid generator, which can generate the grid adaptively.

\until }

With the iterative grid generator, we generate adaptively a sparse grid.

\until }

Then, we hierarchize the function values to get hierarchical B-spline
coefficients of the B-spline sparse grid interpolant
\f$\tilde{f}\colon [0, 1]^d \to \mathbb{R}\f$.

\until ftX0

We define the interpolant \f$\tilde{f}\f$ and its gradient
\f$\nabla\tilde{f}\f$ for use with the gradient method (steepest descent).
Of course, one can also use other optimization algorithms from
sgpp::optimization::optimizer.

\until ft(x0)

The gradient method needs a starting point.
We use a point of our adaptively generated sparse grid as starting point.
More specifically, we use the point with the smallest
(most promising) function value and save it in x0.

\until ft(xOpt)

We apply the gradient method and print the results.

\until }

For comparison, we apply the classical gradient-free Nelder-Mead method
directly to the objective function \f$f\f$.

The example program outputs the following results:
\verbinclude optimization.output.txt

We see that both the gradient-based optimization of the smooth sparse grid
interpolant and the gradient-free optimization of the objective function
find reasonable approximations of the minimum, which lies at
\f$(3\pi/16, 3\pi/14) \approx (0.58904862, 0.67319843)\f$.

The example can be compiled, linked, and executed by
@code
g++ -std=c++11 -O3 -I../../base/src -I../../optimization/src -L../../lib/sgpp -o optimization optimization.cpp -lsgppbase -lsgppoptimization
export LD_LIBRARY_PATH="/PATH_TO_SGPP/lib/sgpp"
./optimization
@endcode
For details see \ref code_examples_tutorial.

\section code_examples_optimization_python Python

The C++ code can be translated into the following Python code.
When run, the example gives (nearly) the same output as the C++ example.

\include optimization.py

\section code_examples_optimization_java Java

The C++ code can be translated into the following Java code.
When run, the example gives (nearly) the same output as the C++ example.

\include optimization.java

The Java and MATLAB examples use this external class:

\include ExampleFunction.java

\section code_examples_optimization_matlab MATLAB

The C++ code can be translated into the following MATLAB code:

\include optimization.m

In the following, we assume that we want to run the example on Linux.

Please note that in order to get sgpp::optimization to work with MATLAB,
you have to disable support for Armadillo and UMFPACK when compiling SG++,
i.e. set USE_ARMADILLO and USE_UMFPACK to "no".
This is due to incompatible BLAS and LAPACK libraries
of Armadillo/UMFPACK and MATLAB
(MATLAB uses instead MKL versions of LAPACK and BLAS
with different pointer sizes of 64 bits).
You can somehow override MATLAB's choice of libraries with
the environmental variables BLAS_VERSION and LAPACK_VERSION,
but this is strongly discouraged as MATLAB itself may produce
unexpected wrong results (e.g., det [1 2; 3 4] = 2).
Static linking to Armadillo and UMFPACK would be
a possible solution to circumvent this problem.

To make SG++ usable within MATLAB, please follow
\ref linux_using_matlab_jsgpp "the instructions provided here (for Linux)".
However, to run the MATLAB example, you additionally need to compile
the class \c ExampleFunction into a \c .jar file
(before starting MATLAB):
\code
javac -cp .:/PATH_TO_SGPP/lib/jsgpp/jsgpp.jar ExampleFunction.java
jar -cf ExampleFunction.jar ExampleFunction.class
\endcode
Under Windows, note that you have to replace the <tt>:</tt> delimiter in
the first line by <tt>;</tt>
(<tt>:</tt> is reserved for the use after the drive letter).
After setting the environment variables and the
\c librarypath.txt correctly
(\ref linux_using_matlab_jsgpp "as described here (for Linux)"),
you can start MATLAB.
In order to run the example, you need to add the example objective
function to MATLAB's Java search path via
\code
javaaddpath('/PATH_TO_SGPP/optimization/examples/ExampleFunction.jar');
\endcode
(i.e., right after adding \c jsgpp.jar to MATLAB's Java path).
Now, you should be able to run the MATLAB example.
When run, the example gives (nearly) the same output as the C++ example.
*/

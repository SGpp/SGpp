/**
@page continued_learning_examples Code Examples: Resuming learning Process

Sometimes one needs to resume the learning process using the saved grid and alpha
files in order to refine the learner or to use some different learning 
parameters. And while the definition of the setup with command line arguments may 
be comfortable for the most common tasks, the default behaviour in this case 
will result in the  recalculating of the last learning iteration. In order to 
change this behaviour the direct interaction with Learner object is needed.
 
This tutorial shows how to create the Learner object using your command line 
arguments as well as how to omit the recomputation of the last iteration resuming
the learning. 

@section continued_learning_examples__overview Overview
- \ref continued_learning_examples__builder_generation
- \ref continued_learning_examples__learning


@section continued_learning_examples__builder_generation Automatic Generation of the Builder code

In order to create a Learner object one should use the @link bin.learner.LearnerBuilder.LearnerBuilder LearnerBuilder @endlink. You can let the @link bin.controller.TerminalController.TerminalController TerminalController @endlink to generate the code from the command line 
arguments. 

Make sure the SG++ project is in your $PYTHONPATH and add it, if it is not
@code 
> export PYTHONPATH=$SGPP_PATH:$PYTHONPATH
@endcode

Let's suppose you learning setup was defined by the following command line
arguments
@code 
> python $SGPP_PATH/bin/classifier.py-v --mode test --data \
/path/to/dataset_train.arff.gz --test /path/to/dataset_test.arff.gz --border \
--level 2 -r 0.0001 -C identity --adapt_points 400 --grid_limit 50000 \
--regression --checkpoint /path/to/checkpoint_file.checkpoint.gz --stats \
/path/to/stats_file.stats.gz --grid /path/to/grid_file.grid.gz --adapt_start 9 \
-L 0.0001
@endcode

With @link bin.controller.TerminalController.TerminalController TerminalController @endlink class you now can automatically generate the code to
create the Learner object using LearnerBuilder. Just call the 
%TerminalController.py with all the command line arguments as above and an 
additional argument @c --generate

@code
> python $SGPP_PATH/bin/controller/TerminalController.py --generate -v --mode \
test --data /path/to/dataset_train.arff.gz --test /path/to/dataset_test.arff.gz \
--border --level 2 -r 0.0001 -C identity --adapt_points 400 --grid_limit 50000 \
--regression --checkpoint /path/to/checkpoint_file.checkpoint.gz --stats \
/path/to/stats_file.stats.gz --grid /path/to/grid_file.grid.gz --adapt_start 9 \
-L 0.0001
@endcode

This will result in the following output:

@code
builder = LearnerBuilder()
builder.buildRegressor()
builder.withTrainingDataFromARFFFile('/path/to/dataset_train.arff.gz')
builder.withTestingDataFromARFFFile('/path/to/dataset_test.arff.gz')
builder = builder.withGrid()
builder.fromFile('/path/to/grid_file.grid.gz')
builder.withStartingIterationNumber(9)
builder = builder.withSpecification()
builder.withAdaptPoints(400)
builder.withLambda(0.00010000000000000000)
builder.withIdentityOperator()
builder = builder.withStopPolicy()
builder.withGridSizeLimit(50000)
builder = builder.withCGSolver()  
builder.withAccuracy(0.000100)
builder.withImax(500)
builder.withProgressPresenter(InfoToScreenRegressor())
builder.withProgressPresenter(InfoToFile('/path/to/stats_file.stats.gz'))
checkpointController = CheckpointController('checkpoint_file.checkpoint.gz', 
'/path/to')
builder.withCheckpointController(checkpointController)
@endcode 

You can then use this output to generate the Learner object. 
@dontinclude grid_refinement.py
Firstly, import all classes used in the generated code segment
@until InfoToFile

Secondly, past the code as a string into your script
@until Controller)"""

Now you can execute the code and obtain the Learner object with
@until andGetResult()



@section continued_learning_examples__learning Resuming the Learning without Recalculating the last Step

Usually if you want to restart your classifier from the checkpoint and to 
perform some more learning iterations, you had to repeat last iteration step 
even so you already have the alpha vector. Depending on the problem size this 
recomputation can be very expensive. This section shows how you can omit it.

Once the Learner object is loaded, e.g., as showed above, update results
to recalculate errors per grid points and refine the grid

@until .refineGrid()

And continue the learning process

@until .learnDataWithTest()

The example script can be found in the file @c examples/grid_refinement.py. 

**/

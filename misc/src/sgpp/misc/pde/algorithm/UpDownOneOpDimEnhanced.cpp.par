/* *****************************************************************************
* Copyright (C) 2012 Technische Universitaet Muenchen                          *
* This file is part of the SG++ project. For conditions of distribution and    *
* use, please see the copyright notice at http://www5.in.tum.de/SGpp           *
***************************************************************************** */
// @author Alexander Heinecke (Alexander.Heinecke@mytum.de)

#include "misc/pde/algorithm/UpDownOneOpDimEnhanced.hpp"

namespace sg
{
namespace pde
{

UpDownOneOpDimEnhanced::UpDownOneOpDimEnhanced(sg::base::GridStorage* storage, sg::base::DataVector& coef) : storage(storage), coefs(&coef), algoDims(storage->getAlgorithmicDimensions()), numAlgoDims_(storage->getAlgorithmicDimensions().size()), numParGradDims_(2)
{
}

UpDownOneOpDimEnhanced::UpDownOneOpDimEnhanced(sg::base::GridStorage* storage) : storage(storage), coefs(NULL), algoDims(storage->getAlgorithmicDimensions()), numAlgoDims_(storage->getAlgorithmicDimensions().size()), numParGradDims_(2)
{
}

UpDownOneOpDimEnhanced::~UpDownOneOpDimEnhanced()
{
}

void UpDownOneOpDimEnhanced::mult(sg::base::DataVector& alpha, sg::base::DataVector& result)
{
	result.setAll(0.0);
	sg::base::DataMatrix maAlpha(alpha.getSize(), 2);
	maAlpha.expand(alpha);
	sg::base::DataMatrix maAlpha1(alpha.getSize(), 1);
	maAlpha1.expand(alpha);

	#pragma omp parallel
	{
		#pragma omp single nowait
		{
			size_t i;
			for (i = 0; i < this->numAlgoDims_-1; i+=2)
			{
				#pragma omp task firstprivate(i) shared(maAlpha, result)
				{
					sg::base::DataMatrix beta(result.getSize(), 2);

					this->updown(maAlpha, beta, this->numAlgoDims_ - 1, i, 2);

					if (coefs == NULL)
					{
						#pragma omp critical
						{
							beta.addReduce(result);
						}
					}
					else
					{
						#pragma omp critical
						{
							beta.addReduce(result, *coefs, i);
						}
					}
				}
			}
			for ( ; i < this->numAlgoDims_; i++)
			{
				#pragma omp task firstprivate(i) shared(maAlpha1, result)
				{
					sg::base::DataMatrix beta(result.getSize(), 1);

					this->updown(maAlpha1, beta, this->numAlgoDims_ - 1, i, 1);

					if (coefs == NULL)
					{
						#pragma omp critical
						{
							beta.addReduce(result);
						}
					}
					else
					{
						#pragma omp critical
						{
							beta.addReduce(result, *coefs, i);
						}
					}
				}

			}

			#pragma omp taskwait
		}
	}
}

void UpDownOneOpDimEnhanced::multParallelBuildingBlock(sg::base::DataVector& alpha, sg::base::DataVector& result)
{
    result.setAll(0.0);
	sg::base::DataMatrix maAlpha(alpha.getSize(), 2);
	maAlpha.expand(alpha);
	sg::base::DataMatrix maAlpha1(alpha.getSize(), 1);
	maAlpha1.expand(alpha);

	size_t i;
	for (i = 0; i < this->numAlgoDims_-1; i+=2)
	{
		#pragma omp task firstprivate(i) shared(maAlpha, result)
		{
			sg::base::DataMatrix beta(result.getSize(), 2);

			this->updown(maAlpha, beta, this->numAlgoDims_ - 1, i, 2);

			if (coefs == NULL)
			{
				#pragma omp critical
				{
					beta.addReduce(result);
				}
			}
			else
			{
				#pragma omp critical
				{
					beta.addReduce(result, *coefs, i);
				}
			}
		}
	}
	for ( ; i < this->numAlgoDims_; i++)
	{
		#pragma omp task firstprivate(i) shared(maAlpha1, result)
		{
			sg::base::DataMatrix beta(result.getSize(), 1);

			this->updown(maAlpha1, beta, this->numAlgoDims_ - 1, i, 1);

			if (coefs == NULL)
			{
				#pragma omp critical
				{
					beta.addReduce(result);
				}
			}
			else
			{
				#pragma omp critical
				{
					beta.addReduce(result, *coefs, i);
				}
			}
		}
	}

}

void UpDownOneOpDimEnhanced::updown(sg::base::DataMatrix& alpha, sg::base::DataMatrix& result, size_t dim, size_t start_grad_dim, size_t num_grad_dims)
{
	//Unidirectional scheme
	if(dim > 0)
	{
		// Reordering ups and downs
		sg::base::DataMatrix temp(alpha.getNrows(), num_grad_dims);
		sg::base::DataMatrix result_temp(alpha.getNrows(), num_grad_dims);
		sg::base::DataMatrix temp_two(alpha.getNrows(), num_grad_dims);

		#pragma omp task if(this->numAlgoDims_ - dim <= this->maxParallelDims_) shared(alpha, temp, result)
		{
			up(alpha, temp, dim, start_grad_dim, num_grad_dims);
			updown(temp, result, dim-1, start_grad_dim, num_grad_dims);
		}

		#pragma omp task if(this->numAlgoDims_ - dim <= this->maxParallelDims_) shared(alpha, temp_two, result_temp)
		{
			updown(alpha, temp_two, dim-1, start_grad_dim, num_grad_dims);
			down(temp_two, result_temp, dim, start_grad_dim, num_grad_dims);
		}

		#pragma omp taskwait

		result.add(result_temp);
	}
	else
	{
		// Terminates dimension recursion
		sg::base::DataMatrix temp(alpha.getNrows(), num_grad_dims);

		#pragma omp task if(this->numAlgoDims_ - dim <= this->maxParallelDims_) shared(alpha, result)
		{
			up(alpha, result, dim, start_grad_dim, num_grad_dims);
		}

		#pragma omp task if(this->numAlgoDims_ - dim <= this->maxParallelDims_) shared(alpha, temp)
		{
		    down(alpha, temp, dim, start_grad_dim, num_grad_dims);
		}

		#pragma omp taskwait

		result.add(temp);
	}
}

}
}
